{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NarreddulaChandrika/chandrika/blob/main/Copy_of_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYEdHQvw0FRq"
      },
      "source": [
        "eee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6v5Ey2_rPl1"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import pandas as pd\n",
        "import helper\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGa-zx6IrPie"
      },
      "outputs": [],
      "source": [
        "english_sentences = pd.read_csv('/content/drive/MyDrive/small_vocab_en.txt', sep = '\\t', names = ['english'])\n",
        "french_sentences = pd.read_csv('/content/drive/MyDrive/small_vocab_fr.txt', sep = '\\t', names = ['french'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDL5G5jyR3bv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReBinpeKrPgq"
      },
      "outputs": [],
      "source": [
        "english_sentences=english_sentences['english'].tolist()\n",
        "french_sentences=french_sentences['french'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI70yugNrPd-",
        "outputId": "bd6487b3-3992-49b8-8ca2-8a9c0f180d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
            "small_vocab_fr Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"
          ]
        }
      ],
      "source": [
        "for sample_i in range(2):\n",
        "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
        "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7bnx-ylrPb3"
      },
      "outputs": [],
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUu2bBvhrPZh",
        "outputId": "0dfee75b-c73f-4624-dcb1-940227059a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
            "Sequence 3 in x\n",
            "  Input:  This is a short sentence .\n",
            "  Output: [18, 19, 3, 20, 21]\n"
          ]
        }
      ],
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    x_tk = Tokenizer()\n",
        "    x_tk.fit_on_texts(x)\n",
        "\n",
        "    return x_tk.texts_to_sequences(x), x_tk\n",
        "\n",
        "# Tokenize Example output\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfh7kcW6rPXU",
        "outputId": "13082b58-f2f1-49df-c089-9214542636ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "def pad(x, length=None):\n",
        "    \"\"\"\n",
        "    Pad x\n",
        "    :param x: List of sequences.\n",
        "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "    :return: Padded numpy array of sequences\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    length = max(map(len,x)) if length is None else length\n",
        "\n",
        "    return pad_sequences(x, maxlen=length, padding='post')\n",
        "\n",
        "# Pad Tokenized output\n",
        "test_pad = pad(text_tokenized)\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsDPJGHPrPU0",
        "outputId": "bf93fe6d-02b9-46bc-b7b5-41f1dfbd0d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 15\n",
            "Max French sentence length: 21\n",
            "English vocabulary size: 199\n",
            "French vocabulary size: 344\n"
          ]
        }
      ],
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(english_sentences, french_sentences)\n",
        "\n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV_b1G-irPSr"
      },
      "outputs": [],
      "source": [
        "def final_predictions(text):\n",
        "  y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "\n",
        "  sentence = [english_tokenizer.word_index[word] for word in text.split()]\n",
        "  sentence = pad_sequences([sentence], maxlen=preproc_french_sentences.shape[-2], padding='post')\n",
        "\n",
        "  return logits_to_text(model1.predict(sentence[:1])[0], french_tokenizer)\n",
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "\n",
        "  #So basically we are predicting output for a given word and then selecting best answer\n",
        "  #Then selecting that label we reverse-enumerate the word from id\n",
        "  r= ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "  return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFa0FuHarPQy"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('/content/drive/MyDrive/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPm3kcvcrPOx"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def ret(txt):\n",
        "  try:\n",
        "    k=final_predictions(re.sub(r'[^\\w]', ' ', txt))\n",
        "    k=k.replace('<PAD>','')\n",
        "  except:\n",
        "    k='invalid sentence give another one'\n",
        "  return k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02D51Byz0MHw"
      },
      "source": [
        "eee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geIrD_RXrPME"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPAJTIiVrPKD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWsh8gKfrPHW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxxugFXkrPE-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XhaDlrlrPCk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvSxdcy2rOzB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApfS5SY30STv"
      },
      "source": [
        "eee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeNi3Pebw_zg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq2pF1vUy4tL",
        "outputId": "8c506bf8-f159-469d-89f6-e6ffcfb14536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/speech.zip\n",
            "  inflating: ArticlesApril2017.csv   \n",
            "  inflating: ArticlesApril2018.csv   \n",
            "  inflating: ArticlesFeb2017.csv     \n",
            "  inflating: ArticlesFeb2018.csv     \n",
            "  inflating: ArticlesJan2017.csv     \n",
            "  inflating: ArticlesJan2018.csv     \n",
            "  inflating: ArticlesMarch2017.csv   \n",
            "  inflating: ArticlesMarch2018.csv   \n",
            "  inflating: ArticlesMay2017.csv     \n",
            "  inflating: CommentsApril2017.csv   \n",
            "  inflating: CommentsApril2018.csv   \n",
            "  inflating: CommentsFeb2017.csv     \n",
            "  inflating: CommentsFeb2018.csv     \n",
            "  inflating: CommentsJan2017.csv     \n",
            "  inflating: CommentsJan2018.csv     \n",
            "  inflating: CommentsMarch2017.csv   \n",
            "  inflating: CommentsMarch2018.csv   \n",
            "  inflating: CommentsMay2017.csv     \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/speech.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N55WrDX_y0pK",
        "outputId": "445c0fe4-e94a-4881-c735-152ca4b7751c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' G.O.P. Leadership Poised to Topple Obama’s Pillars',\n",
              " 'Fractured World Tested the Hope of a Young President',\n",
              " 'Little Troublemakers',\n",
              " 'Angela Merkel, Russia’s Next Target',\n",
              " 'Boots for a Stranger on a Bus']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "curr_dir = '/content/'\n",
        "all_headlines = []\n",
        "for filename in os.listdir(curr_dir):\n",
        "    if 'Articles' in filename:\n",
        "        article_df = pd.read_csv(curr_dir + filename)\n",
        "        all_headlines.extend(list(article_df.headline.values))\n",
        "        break\n",
        "all_headlines = [line for line in all_headlines if line!= \"Unknown\"]\n",
        "all_headlines[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP021XTKzMt9",
        "outputId": "bf86f35f-7e39-401e-9f25-73445243e0bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' gop leadership poised to topple obamas pillars',\n",
              " 'fractured world tested the hope of a young president',\n",
              " 'little troublemakers',\n",
              " 'angela merkel russias next target',\n",
              " 'boots for a stranger on a bus']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_s1(txt):\n",
        "    txt = \"\".join(t for t in txt if t not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt\n",
        "corpus = [clean_s1(x) for x in all_headlines]\n",
        "corpus[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvfPVwTPzS5V",
        "outputId": "398295b2-5fbc-4de2-e23a-3a15df2d1af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[73, 313],\n",
              " [73, 313, 616],\n",
              " [73, 313, 616, 3],\n",
              " [73, 313, 616, 3, 617],\n",
              " [73, 313, 616, 3, 617, 205],\n",
              " [73, 313, 616, 3, 617, 205, 314],\n",
              " [618, 38],\n",
              " [618, 38, 619]]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "input_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "input_sequences[:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8rBCladzVW4",
        "outputId": "75a02205-8314-42d3-aa3b-83eb312a20d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gop leadership \n",
            "gop leadership poised \n",
            "gop leadership poised to \n",
            "gop leadership poised to topple \n",
            "gop leadership poised to topple obamas \n",
            "gop leadership poised to topple obamas pillars \n",
            "fractured world \n",
            "fractured world tested \n"
          ]
        }
      ],
      "source": [
        "for j in range(8):\n",
        "    s = input_sequences[j]\n",
        "    for i in range(1, len(s)+1):\n",
        "        print(tokenizer.index_word[s[i-1]], end = ' ')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2f9NzvBzXl1",
        "outputId": "013066e1-c0bb-4442-869b-a43365c6c4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of Max Sequence: 20\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 73] 313\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  73 313] 616\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  73\n",
            " 313 616] 3\n"
          ]
        }
      ],
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence = generate_padded_sequences(input_sequences)\n",
        "max_sequence = max_sequence-1\n",
        "print(\"Length of Max Sequence:\",max_sequence)\n",
        "for i in range(3):\n",
        "    print(predictors[i], list(label[i]).index(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M_br5d60XQ9",
        "outputId": "28be7569-45f3-4143-b040-9a892be6ea2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2217"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4JJT83Y0UXM"
      },
      "source": [
        "eee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k1pE5y20ZVd"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words,20,input_length=max_sequence))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True)))\n",
        "model.add(LSTM(units=100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=total_words, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sEDPs950b2Z",
        "outputId": "d85ac30a-e205-4625-deed-cb128f4158d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 20)            44340     \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 20, 200)           96800     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               120400    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2217)              223917    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 485457 (1.85 MB)\n",
            "Trainable params: 485457 (1.85 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "en5Yt2HU0d6k",
        "outputId": "32d06648-5017-44f5-c269-ce2dde92223d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6303916e60>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(predictors,label,epochs=100,verbose=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YzUi4s_-aZi",
        "outputId": "d96d0d87-3d0d-4d05-d834-43294066da60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-4e625edfd19d>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(model, \"prompt.h5\")\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "save_model(model, \"prompt.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39sM8xfQ0XdP"
      },
      "source": [
        "eee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjbuuxJn--ke"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# load model\n",
        "model2 = load_model('/content/prompt.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvgEfYNinYUQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0dmeFwd0gP-",
        "outputId": "20e2a2a2-6249-4a80-f907-90bbb8b9658f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "I know how to partisan partisan\n"
          ]
        }
      ],
      "source": [
        "def make_pred(sentence, limit):\n",
        "    for i in range(limit):\n",
        "        tokenized_words = tokenizer.texts_to_sequences([sentence])[0]\n",
        "        tokenized_words = pad_sequences([tokenized_words], maxlen=max_sequence, padding='pre')\n",
        "        pred_word = np.argmax(model2.predict(tokenized_words))\n",
        "        pred = tokenizer.index_word[pred_word]\n",
        "        sentence += \" \" + pred\n",
        "    return sentence\n",
        "\n",
        "sentence = \"I know how to\"\n",
        "length_words = 2\n",
        "output_pred = make_pred(sentence,length_words)\n",
        "print(output_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1I0r9e2jcbw",
        "outputId": "14fafff9-c372-487d-9d33-f81556b6c491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[32m-\u001b[0m \u001b[32m0 bytes\u001b[0m \u001b[31m?\u001b[0m \u001b[33m0:00:00\u001b[0m\r\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m3.0 kB\u001b[0m \u001b[31m?\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for Deep-Learning-Colab-Notebook-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting speechRecognition\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechRecognition) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechRecognition) (2024.2.2)\n",
            "Installing collected packages: speechRecognition\n",
            "Successfully installed speechRecognition-3.10.1\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.1\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.27.0)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.31.0)\n",
            "Requirement already satisfied: tornado==6.3.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.27.0->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (3.1.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker==1.5.2->google-colab) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2024.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.27.0->google-colab) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->google-colab) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.21)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=0967d48e6995460da20308fa2f527310e84874d2a0032bb811abc4f6f323a2a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting wolframalpha\n",
            "  Downloading wolframalpha-5.0.0-py3-none-any.whl (7.5 kB)\n",
            "Collecting xmltodict (from wolframalpha)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from wolframalpha) (10.1.0)\n",
            "Collecting jaraco.context (from wolframalpha)\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: xmltodict, jaraco.context, wolframalpha\n",
            "Successfully installed jaraco.context-4.3.0 wolframalpha-5.0.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "!pip install speechRecognition\n",
        "!pip install gTTS\n",
        "!pip install google-colab\n",
        "\n",
        "!pip install wikipedia\n",
        "!pip install wolframalpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaYo8krW4nnn"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import Audio, display, clear_output, Javascript\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "import speech_recognition as sr\n",
        "\n",
        "\n",
        "\n",
        "import random #It is used to obtain a random value from a group of values\n",
        "import wikipedia #Used to get articles from wikipedia and summarize them if necessary\n",
        "import wolframalpha #Used in the core of the VA\n",
        "import datetime #Used to get the current time\n",
        "import os #For system related functions\n",
        "import sys #For system related functions\n",
        "from gtts import gTTS\n",
        "import librosa\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "graBlqB844H1"
      },
      "outputs": [],
      "source": [
        "\n",
        "SAMPLE_RATE = 16000\n",
        "record_seconds =   3#@param {type:\"number\", min:1, max:10, step:1}\n",
        "text_recognized = \"default_text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmEdkHxN5fXY"
      },
      "outputs": [],
      "source": [
        "def speak(to_speak=\"Default\"):\n",
        "  tts = gTTS(to_speak) #Provide the string to convert to speech\n",
        "  tts.save('out.wav') #save the string converted to speech as a .wav file\n",
        "  sound_file = 'out.wav'\n",
        "  display(Audio(sound_file, autoplay=True))\n",
        "  time.sleep(librosa.get_duration(filename='out.wav'))\n",
        "  return 200\n",
        "\n",
        "def _recognize(audio):\n",
        "  # display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  wavfile.write('in.wav', SAMPLE_RATE, (32767*audio).astype(np.int16))\n",
        "  print('\\n')\n",
        "  filename = \"in.wav\"\n",
        "  r = sr.Recognizer()\n",
        "  with sr.AudioFile(filename) as source:\n",
        "      # listen for the data (load audio to memory)\n",
        "      try:\n",
        "        audio_data = r.record(source)\n",
        "        # recognize (convert from speech to text)\n",
        "        text = r.recognize_google(audio_data)\n",
        "        return text\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Could you speak more clearly\")\n",
        "        return \"None\"\n",
        "\n",
        "\n",
        "def _record_audio():\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  text_recognized = _recognize(audio)\n",
        "  print(f\"Users says: {text_recognized}\\n\")\n",
        "  return text_recognized\n",
        "\n",
        "def takeCommand():\n",
        "  button = widgets.Button(description=\"Record Speech\")\n",
        "  return _record_audio()\n",
        "  # button.on_click(_record_audio)\n",
        "  # display(button)\n",
        "\n",
        "def open_web(url):\n",
        "    display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
        "\n",
        "def wishMe():\n",
        "    hour = int(datetime.datetime.now().hour)\n",
        "    if hour>= 0 and hour<12:\n",
        "        speak(\"Good Morning Sir !\")\n",
        "    elif hour>= 12 and hour<18:\n",
        "        speak(\"Good Afternoon Sir !\")\n",
        "    else:\n",
        "        speak(\"Good Evening Sir !\")\n",
        "    name =(\"translator\")\n",
        "    speak(\"I am your Assistant\")\n",
        "    speak(name)\n",
        "\n",
        "def usrname():\n",
        "    speak(\"What should i call you sir\")\n",
        "    uname = takeCommand()\n",
        "    speak(\"Welcome\")\n",
        "    speak(uname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1fRvDbV_WYq"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def bot(query=\"\"):\n",
        "    k=True\n",
        "    while k==True:\n",
        "        speak(\"How can I help you\")\n",
        "        time.sleep(1)\n",
        "        query = takeCommand().lower()\n",
        "        print(query)\n",
        "        if 'wikipedia' in query:\n",
        "            speak('Searching Wikipedia...')\n",
        "            query = query.replace(\"wikipedia\", \"\")\n",
        "            results = wikipedia.summary(query, sentences = 3)\n",
        "            speak(\"Here is what wikipedia says\")\n",
        "            print(results)\n",
        "            speak(results)\n",
        "            k=True\n",
        "\n",
        "        elif 'open youtube' in query:\n",
        "            speak(\"Yes opening\")\n",
        "            open_web('https://www.youtube.com');\n",
        "            k=True\n",
        "\n",
        "        elif 'open forum' in query:\n",
        "            speak(\"Yes opening \" + str(\"forum.aistudent.community\"))\n",
        "            open_web(\"https://www.forum.aistudent.community\")\n",
        "            k=True\n",
        "\n",
        "        elif 'open google' in query:\n",
        "            speak(\"Yes opening \" + str(\"www.google.co.in\"))\n",
        "            open_web(\"https://www.google.co.in\")\n",
        "            k=True\n",
        "\n",
        "        elif 'open stack overflow' in query:\n",
        "            speak(\"Yes opening \" + str(\"stackoverflow.com\"))\n",
        "            open_web(\"https://www.stackoverflow.com\")\n",
        "            k=True\n",
        "\n",
        "        elif 'how are you' in query:\n",
        "            speak(\"I am fine, Thank you\")\n",
        "            speak(\"How are you, opening \" + str())\n",
        "            k=True\n",
        "\n",
        "        elif 'fine' in query or \"good\" in query:\n",
        "            speak(\"It's good to know that your fine\")\n",
        "            k=True\n",
        "\n",
        "        elif \"change name\" in query:\n",
        "            speak(\"What would you like to call me, Sir \")\n",
        "            name = takeCommand()\n",
        "            speak(\"Thanks for naming me\")\n",
        "            k=True\n",
        "\n",
        "        elif \"what's your name\" in query or \"What is your name\" in query:\n",
        "            speak(\"My friends call me\")\n",
        "            name =(\"Arnold\")\n",
        "            speak(name)\n",
        "            print(\"My friends call me\", name)\n",
        "            k=True\n",
        "\n",
        "        elif 'search' in query or 'play' in query:\n",
        "            query = query.replace(\"search\", \"\")\n",
        "            query = query.replace(\"play\", \"\")\n",
        "            open_web(query)\n",
        "            k=True\n",
        "\n",
        "        elif \"who are you\" in query:\n",
        "            speak(\"I am your virtual assistant\")\n",
        "            k=True\n",
        "\n",
        "        elif \"where is\" in query:\n",
        "            query = query.replace(\"where is\", \"\")\n",
        "            location = query\n",
        "            speak(\"User asked to Locate\")\n",
        "            speak(location)\n",
        "            open_web(\"https://www.google.com/maps/search/?api=1&\" + location + \"\")\n",
        "            k=True\n",
        "\n",
        "        elif \"will you be my friend\" in query:\n",
        "            speak(\"Sure, why not\")\n",
        "            k=True\n",
        "        elif \"generate text\" in query:\n",
        "            speak(\"give a prompt\")\n",
        "            prompt = takeCommand().lower()\n",
        "            speak(\"set the limit\")\n",
        "            length = takeCommand().lower()\n",
        "            if length == 'none':\n",
        "              speak(make_pred(prompt, 10))\n",
        "            else:\n",
        "              speak(make_pred(prompt, int(length)))\n",
        "            k=True\n",
        "            time.sleep(3)\n",
        "        elif \"translate\" in query:\n",
        "          t=True\n",
        "          while t:\n",
        "            speak(\"give me a sentence to translate\")\n",
        "            txt=takeCommand().lower()\n",
        "            p=ret(txt)\n",
        "            if \"invalid\" in p:\n",
        "              speak(p)\n",
        "              t=True\n",
        "            else:\n",
        "              speak(p)\n",
        "              t=False\n",
        "          time.sleep(2)\n",
        "\n",
        "\n",
        "        elif 'exit' in query:\n",
        "            speak(\"Thanks for giving me your time\")\n",
        "            k=False\n",
        "            exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "9TUuVCWJVsh4",
        "outputId": "af6a14e9-b14a-4212-a6fc-4908b3608678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting recording for 3 seconds...\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "      const b2text = blob => new Promise(resolve => {\n",
              "        const reader = new FileReader()\n",
              "        reader.onloadend = e => resolve(e.srcElement.result)\n",
              "        reader.readAsDataURL(blob)\n",
              "      })\n",
              "      var record = time => new Promise(async resolve => {\n",
              "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "        recorder = new MediaRecorder(stream)\n",
              "        chunks = []\n",
              "        recorder.ondataavailable = e => chunks.push(e.data)\n",
              "        recorder.start()\n",
              "        await sleep(time)\n",
              "        recorder.onstop = async ()=>{\n",
              "          blob = new Blob(chunks)\n",
              "          text = await b2text(blob)\n",
              "          resolve(text)\n",
              "        }\n",
              "        recorder.stop()\n",
              "      })\n",
              "      "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished recording!\n",
            "\n",
            "\n",
            "Users says: exit\n",
            "\n",
            "exit\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-ce6ee7c19223>:6: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  time.sleep(librosa.get_duration(filename='out.wav'))\n"
          ]
        }
      ],
      "source": [
        "bot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neXVlt_40qZ3"
      },
      "source": [
        "eee final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7_zI5uECqoi",
        "outputId": "965a6b23-fef5-4da5-e879-cc4dc94af6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/en-fr.csv.zip, /content/drive/MyDrive/en-fr.csv.zip.zip or /content/drive/MyDrive/en-fr.csv.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/en-fr.csv.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ldSxu2aUth"
      },
      "outputs": [],
      "source": [
        "#import all libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,LSTM, Dropout\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ljWVmgPtaiK1",
        "outputId": "518d5572-8bd3-4ace-f3f4-4a84a8523e9c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/en-fr.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c12d2e22353e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/en-fr.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/en-fr.csv'"
          ]
        }
      ],
      "source": [
        "df  =pd.read_csv('/content/en-fr.csv',nrows=20000)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9ii4uL1alo2"
      },
      "outputs": [],
      "source": [
        "eng = df['en']\n",
        "fr = df['fr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9cRpKWP3aoT7",
        "outputId": "c43f4343-a26d-4c46-c93e-d5516f5f284e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'collections' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-666a7accf3ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menglish_words_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meng\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfrench_words_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} English words.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meng\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} unique English words.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_words_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "english_words_counter = collections.Counter([word for sentence in eng for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in fr for word in sentence.split()])\n",
        "\n",
        "print('{} English words.'.format(len([word for sentence in eng for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} French words.'.format(len([word for sentence in fr for word in sentence.split()])))\n",
        "print('{} unique French words.'.format(len(french_words_counter)))\n",
        "print('10 Most common words in the French dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxr15fVdapND"
      },
      "outputs": [],
      "source": [
        "def tokenize(x):\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngmi6HAnasvk"
      },
      "outputs": [],
      "source": [
        "def pad(x, length=None):\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = 55, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8uVLWf0awCH"
      },
      "outputs": [],
      "source": [
        "def preprocess(x, y):\n",
        "\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODnR_mOebheA"
      },
      "outputs": [],
      "source": [
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(eng, fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P2cF969bmiZ"
      },
      "outputs": [],
      "source": [
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2ad7SnnbpUp"
      },
      "outputs": [],
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vvix52AbsFP"
      },
      "outputs": [],
      "source": [
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "\n",
        "    learning_rate = 0.003\n",
        "\n",
        "    # Build the layers\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(french_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
        "    model.add(Bidirectional(GRU(256, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(english_vocab_size, activation='softmax')))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mun3kxrDbu3x"
      },
      "outputs": [],
      "source": [
        "tmp_x.shape\n",
        "preproc_english_sentences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_dKtlhjb0-Y"
      },
      "outputs": [],
      "source": [
        "# Reshape the input\n",
        "tmp_x = pad(preproc_french_sentences, preproc_french_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))\n",
        "\n",
        "# Train\n",
        "model = bd_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_english_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(tmp_x, preproc_english_sentences, batch_size=64, epochs=5, validation_split=0.2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}